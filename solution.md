С созданием протофайла все в целом ясно. Создаем структуры для обычного сообщения, для response, для request и описываем gRPC интерфейс 
сервера - rpc SendMessage, принимающий request и возвращающий response. rpc ReadMessages без полей (Empty) и возвращающий поток сообщений.

Теперь перейдем к реализации сервера. Из примеров с семинаров (gRPC streaming queue) понимаем, что нужно реализовать класс MessengerService.
В инициализации заводим список клиентов (self._clients) и lock для работы с многопоточкой. Сначала реализуем SendMessage. В самом начале с помощью Timestamp()
поймем send_time. Теперь с помощью переданных нам в функцию author и text создаем message, который передаем в каждый из "буфферов" клиентов.
Не забываем это делать под Lock и возвращаем response с вышепосчитанным send_time.

Теперь перейдем к реализации ReadMessages. Для начала создаем новый buffer, являющимся SimpleQueue для потокобезопасности (по совету из readme этой домашки)
Под локом добавляем buffer в список буфферов клиентов. Затем начинаем чтение из этого буфера. Используем для этого while true и try.
Если buffer не пуст - забираем оттуда самое первое сообщение и возвращаем его (одновременно удаляя из начала очереди). Если же очередь была пуста - проверяем,
есть ли все еще connect с клиентом. Если нет - прекращаем работу while. После завершения работы while не забываем удалить buffer из списка клиентов.

Реализация класса сервера на этом заканчивается, осталось его запустить. Это делается обычным шаблоном, который можно подсмотреть в той же
реализации gRPC streaming queue. max_workers устанавливаем на 10, тк этого по идее должно точно хватить при двух клиентов. (по 2 потока на
каждый из ReadMessages, дальше потоки выделяются только на быстрые SendMessage)

Теперь реализуем клиент. За основу берем уже написанный за нас client.py. Реализуем _send_message. Создаем message_request с помощью json парсера
С помощью stub удаленно вызываем SendMessage от message_request и сохраняем response. И затем обратно в json формат перегоняем response и возвращаем
его.

Создадим так же функцию для "чтения" потока сообщений и сохранений их в Postbox - потокобезопасного буффера для хранения пришедших кленту сообщений.
Назовем функцию consume_messages. Тогда просто запустим цикл for message in stub.ReadMessages(empty, wait_for_ready=True):, где message - будут
являться сообщениями из возвращаемого потока сообщений ReadMessages. Каждое такое сообщения вновь перегоняем в json формат и закидываем его в postbox.
Интересный факт - без true флага wait_for_ready, решение заходило лишь на 6 баллов и не проходило test_clients, тк сервер может инициализироваться
позже клиента.

Осталось установить соединение между клиентом и сервером. У нас есть grpc_server_address. Создаем с помощью него gRPC канал, по которому
"подключаем" stub. Создаем объект postbox, являющийся заранее реализованным классом потокобезопасного буффера. Запускаем gRPC stream ReadMessages,
а именно передаем функцию consume_messages в поток с аргументами stub и postbox. Флаг daemon=True нужен для того, чтобы поток завершился
при завершении работы HTTP сервера (не проверял, будет ли работать без данного флага). Дальнейший запуск HTTP сервера уже написан за нас.

Теперь осталось написать client.dockerfile и server.dockerfile для сборки нашего мессенджера. Берем за основу dockerfile который уже был
написан в папке templates и редактируем его под наши нужды (редактировать по сути ничего и не пришлось). Задача сделана.